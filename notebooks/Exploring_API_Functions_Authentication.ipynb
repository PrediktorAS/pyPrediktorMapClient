{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages and libraries\n",
    "import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import pandas as pd\n",
    "from requests.exceptions import HTTPError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprediktormapclient.opc_ua import OPC_UA\n",
    "from pyprediktormapclient.model_index import ModelIndex\n",
    "from pyprediktormapclient.auth_client import AUTH_CLIENT\n",
    "from pyprediktormapclient.analytics_helper import AnalyticsHelper\n",
    "from pyprediktormapclient.shared import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Envrionment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider obtaining the envrionment variables from .env file if you are running this locally from source.\n",
    "dotenv_path = Path(\"../.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ[\"USERNAME\"]\n",
    "password = os.environ[\"PASSWORD\"]\n",
    "opcua_rest_url = os.environ[\"OPC_UA_REST_URL\"]\n",
    "opcua_server_url = os.environ[\"OPC_UA_SERVER_URL\"]\n",
    "model_index_url = os.environ[\"MODEL_INDEX_URL\"]\n",
    "ory_url = os.environ[\"ORY_URL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ory bearer token\n",
    "auth_client = AUTH_CLIENT(rest_url=ory_url, username=username, password=password)\n",
    "auth_client.request_new_ory_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from modelindex api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to ModelIndex APIs \n",
    "model_data = ModelIndex(url=model_index_url, auth_client=auth_client, session=auth_client.session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listed sites on the model index api server\n",
    "namespaces = model_data.get_namespace_array()\n",
    "namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of Objects\n",
    "object_types_json = model_data.get_object_types()\n",
    "object_types = AnalyticsHelper(object_types_json)\n",
    "object_types.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique types of Objects\n",
    "object_types_unique = object_types.dataframe[[\"Id\", \"Name\"]].drop_duplicates()\n",
    "object_types_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get typeId by type name of an object\n",
    "object_type_id = model_data.get_object_type_id_from_name(\"SiteType\")\n",
    "object_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the objects of a type\n",
    "sites_json = model_data.get_objects_of_type(\"SiteType\")\n",
    "\n",
    "# Send the returned JSON into a normalizer to get Id, Type, Name, Props and Vars as columns\n",
    "sites = AnalyticsHelper(sites_json)\n",
    "sites.list_of_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analytics helper\n",
    "sites.variables_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites.list_of_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the single site\n",
    "site_id = sites.list_of_ids()[0]\n",
    "site_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all stringsets for one park\n",
    "string_sets_for_first_park_as_json = model_data.get_object_descendants(\n",
    "    \"StringSetType\", [site_id], \"PV_Assets\"\n",
    ")\n",
    "string_sets_for_first_park = AnalyticsHelper(string_sets_for_first_park_as_json)\n",
    "string_sets_for_first_park.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancestors of an object type, get all trackers that are ancestor of the parks string sets\n",
    "\n",
    "trackers_as_json = model_data.get_object_ancestors(\n",
    "    \"TrackerType\", string_sets_for_first_park.list_of_ids(), \"PV_Serves\"\n",
    ")\n",
    "trackers = AnalyticsHelper(trackers_as_json)\n",
    "trackers.variables_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_df = sites.variables_as_dataframe()\n",
    "node_ids_list = sites_df['Id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id_dicts = AnalyticsHelper.create_read_value_ids_list_for_event_types(sites)\n",
    "node_id_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_read_value_ids_list_for_event_types(event_type_name_of_node_ids):\n",
    "    \"\"\"\n",
    "    Create a list of NodeId dictionaries from a JSON response.\n",
    "\n",
    "    The function extracts the 'Id' field from the JSON response, splits it into namespace, id type, and id,\n",
    "    and creates a NodeId dictionary for each id. It then removes any duplicates from the list of NodeId dictionaries.\n",
    "    \"\"\"\n",
    "    # Extracting Id column from the dataframe\n",
    "    response_json = model_data.get_objects_of_type(event_type_name_of_node_ids)\n",
    "    json_data = AnalyticsHelper(response_json)\n",
    "\n",
    "    json_df = json_data.variables_as_dataframe()\n",
    "    node_ids_list = json_df['Id'].tolist()\n",
    "\n",
    "    node_id_dicts = []\n",
    "    for id_str in node_ids_list:\n",
    "        parts = id_str.split(\":\")\n",
    "        node_id_dict = {\n",
    "            \"NodeId\": {\n",
    "                \"Id\": parts[2],\n",
    "                \"Namespace\": int(parts[0]),\n",
    "                \"IdType\": int(parts[1]),\n",
    "            }\n",
    "        }\n",
    "        node_id_dicts.append(node_id_dict)\n",
    "\n",
    "    node_id_dicts = [json.loads(t) for t in set(json.dumps(d) for d in node_id_dicts)]\n",
    "    return node_id_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id_dicts = create_read_value_ids_list_for_event_types(\"SiteEventType\")\n",
    "node_id_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from the opc ua api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace_list = object_types.namespaces_as_list(namespaces)\n",
    "\n",
    "# Initating the OPC UA API with a fixed namespace list\n",
    "opc_data = OPC_UA(\n",
    "    rest_url=opcua_rest_url, opcua_url=opcua_server_url, namespaces=namespace_list, auth_client=auth_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all event types\n",
    "event_types = opc_data.get_event_types(\"SiteEventType\")\n",
    "event_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_noded_id = \"6:0:1070\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_historical_events(opc_data,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    event_type_noded_id,\n",
    "    node_id_dicts,\n",
    "    fields_list= None,\n",
    "    limit_start_index = None,\n",
    "    limit_num_records = None,\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "    #event_type_noded_id = opc_data.get_event_types(event_type_name)\n",
    "\n",
    "    body = copy.deepcopy(opc_data.body)\n",
    "    body[\"StartTime\"] = start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    body[\"EndTime\"] = end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    body[\"Fields\"] = fields_list if fields_list else []\n",
    "    body[\"WhereClause\"] = {\n",
    "            \"EventTypeNodedId\": {\n",
    "                \"Id\": int(event_type_noded_id.split(\":\")[2]),\n",
    "                \"Namespace\": int(event_type_noded_id.split(\":\")[0]),\n",
    "                \"IdType\": int(event_type_noded_id.split(\":\")[1])\n",
    "            }\n",
    "        }\n",
    "    body[\"ReadValueIds\"] = node_id_dicts\n",
    "\n",
    "    if limit_start_index is not None and limit_num_records is not None:\n",
    "        body[\"Limit\"] = {\n",
    "            \"StartIndex\": limit_start_index,\n",
    "            \"NumRecords\": limit_num_records\n",
    "        }\n",
    "    print(body)\n",
    "\n",
    "    try:\n",
    "        # Try making the request, if fails check if it is due to ory client\n",
    "        content = request_from_api(\n",
    "            rest_url=opcua_rest_url,\n",
    "            method=\"POST\",\n",
    "            endpoint=\"events/read\",\n",
    "            data=json.dumps(body, default=opc_data.json_serial),\n",
    "            headers=opc_data.headers,\n",
    "            extended_timeout=True,\n",
    "        )\n",
    "\n",
    "    except HTTPError as e:\n",
    "        if opc_data.auth_client is not None:\n",
    "            opc_data.check_auth_client(json.loads(e.response.content))\n",
    "        else:\n",
    "            raise RuntimeError(f'Error message {e}')\n",
    "    \n",
    "    df_result = pd.json_normalize(content, record_path=[\"EventsResult\"])\n",
    "    df_hist_event = df_result.explode('HistoryEvents')\n",
    "    df_hist_event_normalized = pd.json_normalize(df_hist_event['HistoryEvents'])\n",
    "    df_hist_event_normalized = df_hist_event_normalized[fields_list]\n",
    "\n",
    "    df_final = pd.concat([df_hist_event[df_hist_event.columns.difference(['HistoryEvents'])].reset_index(drop=True), df_hist_event_normalized.reset_index(drop=True)], axis=1)\n",
    "    new_columns = fields_list + [col for col in df_final.columns if col not in fields_list]\n",
    "    df_final = df_final[new_columns]\n",
    "    df_final.rename(\n",
    "            columns={\n",
    "                \"NodeId.Id\": \"Id\",\n",
    "                \"NodeId.IdType\": \"IdType\",\n",
    "                \"NodeId.Namespace\": \"Namespace\",\n",
    "                \"StatusCode.Code\": \"StatusCode\",\n",
    "                \"StatusCode.Symbol\": \"Quality\",\n",
    "            },\n",
    "            errors=\"raise\",\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "    df_final.drop(columns=[\"IdType\", \"Namespace\", \"StatusCode\", \"Quality\"], inplace=True)\n",
    "    \n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_historical_events1(opc_data,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    event_type_noded_id,\n",
    "    fields_list= None,\n",
    "    limit_start_index = None,\n",
    "    limit_num_records = None,\n",
    "    ) -> pd.DataFrame:\n",
    "\n",
    "    event_type_noded_id \n",
    "\n",
    "    body = copy.deepcopy(opc_data.body)\n",
    "    body[\"StartTime\"] = start_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    body[\"EndTime\"] = end_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    body[\"Fields\"] = fields_list if fields_list else []\n",
    "    body[\"WhereClause\"] = {\n",
    "            \"EventTypeNodedId\": {\n",
    "                \"Id\": int(event_type_noded_id.split(\":\")[2]),\n",
    "                \"Namespace\": int(event_type_noded_id.split(\":\")[0]),\n",
    "                \"IdType\": int(event_type_noded_id.split(\":\")[1])\n",
    "            }\n",
    "        }\n",
    "    body[\"ReadValueIds\"] = [\n",
    "        {\n",
    "        \"NodeId\": {\n",
    "            'Id': 'Enterprise.EG-AS',\n",
    "            'Namespace': 3,\n",
    "            'IdType': 1\n",
    "        }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    if limit_start_index is not None and limit_num_records is not None:\n",
    "        body[\"Limit\"] = {\n",
    "            \"StartIndex\": limit_start_index,\n",
    "            \"NumRecords\": limit_num_records\n",
    "        }\n",
    "    print(body)\n",
    "\n",
    "    try:\n",
    "        # Try making the request, if fails check if it is due to ory client\n",
    "        content = request_from_api(\n",
    "            rest_url=opcua_rest_url,\n",
    "            method=\"POST\",\n",
    "            endpoint=\"events/read\",\n",
    "            data=json.dumps(body, default=opc_data.json_serial),\n",
    "            headers=opc_data.headers,\n",
    "            extended_timeout=True,\n",
    "        )\n",
    "\n",
    "    except HTTPError as e:\n",
    "        if opc_data.auth_client is not None:\n",
    "            opc_data.check_auth_client(json.loads(e.response.content))\n",
    "        else:\n",
    "            raise RuntimeError(f'Error message {e}')\n",
    "    \n",
    "    df_result = pd.json_normalize(content, record_path=[\"EventsResult\"])\n",
    "    df_hist_event = df_result.explode('HistoryEvents')\n",
    "    df_hist_event_normalized = pd.json_normalize(df_hist_event['HistoryEvents'])\n",
    "    df_hist_event_normalized = df_hist_event_normalized[fields_list]\n",
    "\n",
    "    df_final = pd.concat([df_hist_event[df_hist_event.columns.difference(['HistoryEvents'])].reset_index(drop=True), df_hist_event_normalized.reset_index(drop=True)], axis=1)\n",
    "    new_columns = fields_list + [col for col in df_final.columns if col not in fields_list]\n",
    "    df_final = df_final[new_columns]\n",
    "    df_final.rename(\n",
    "            columns={\n",
    "                \"NodeId.Id\": \"Id\",\n",
    "                \"NodeId.IdType\": \"IdType\",\n",
    "                \"NodeId.Namespace\": \"Namespace\",\n",
    "                \"StatusCode.Code\": \"StatusCode\",\n",
    "                \"StatusCode.Symbol\": \"Quality\",\n",
    "            },\n",
    "            errors=\"raise\",\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "    df_final.drop(columns=[\"IdType\", \"Namespace\", \"StatusCode\", \"Quality\"], inplace=True)\n",
    "    \n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_type_noded_id = \"6:0:1070\"\n",
    "start_time=(datetime.datetime.now() - datetime.timedelta(1))\n",
    "end_time=(datetime.datetime.now() - datetime.timedelta(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading historical events data \n",
    "hist_events = read_historical_events1(opc_data,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    event_type_noded_id,\n",
    "    fields_list = [\"Time\", \"Message\", \"Severity\", \"SourceName\"],\n",
    ")\n",
    "hist_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading one month historical events of trackers \n",
    "hist_events = opc_data.read_historical_events(\n",
    "    start_time=(datetime.datetime.now() - datetime.timedelta(30)),\n",
    "    end_time=(datetime.datetime.now() - datetime.timedelta(1)),\n",
    "    event_type_name=\"InverterEventType\",\n",
    "    event_type_node_ids = node_ids_list,\n",
    "    fields_list = [\"Time\", \"Message\", \"Severity\", \"SourceName\"]\n",
    ")\n",
    "hist_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live value data of trackers\n",
    "live_value = opc_data.get_values(\n",
    "    inverters.variables_as_list([\"DCPower\"])\n",
    ")\n",
    "live_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live value data of trackers\n",
    "live_value = opc_data.get_values(\n",
    "    trackers.variables_as_list([\"AngleMeasured\"])\n",
    ")\n",
    "live_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historic value data of trackers, 1 days worth of data 30 days ago\n",
    "one_day_historic_tracker_data = opc_data.get_historical_aggregated_values(\n",
    "    start_time=(datetime.datetime.now() - datetime.timedelta(30)),\n",
    "    end_time=(datetime.datetime.now() - datetime.timedelta(29)),\n",
    "    pro_interval=3600000,\n",
    "    agg_name=\"Average\",\n",
    "    variable_list=trackers.variables_as_list([\"AngleMeasured\"]),\n",
    ")\n",
    "one_day_historic_tracker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_historic_tracker_data[\"Id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trackers.variables_as_list()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trackers.variables_as_list()\n",
    "# Extract the 'Id' values that end with '.Signals.DCPower'\n",
    "angle_measured_ids = [item['Id'] for item in data if item['Id'].endswith('.Signals.AngleMeasured')]\n",
    "\n",
    "unique_dc_power_ids = set(dc_power_ids)\n",
    "unique_dc_power_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_dc_power_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_auth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
